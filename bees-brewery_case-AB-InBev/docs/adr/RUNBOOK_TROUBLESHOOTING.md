# Runbook de Troubleshooting - BEES Brewery Pipeline

**Vers√£o:** 1.1  
**Data:** 1 de Fevereiro de 2026  
**Objetivo:** Guia pr√°tico para diagn√≥stico e resolu√ß√£o de problemas comuns no pipeline Medallion

---

## üìã √çndice R√°pido

1. [Problemas de Execu√ß√£o](#1-problemas-de-execu√ß√£o)
2. [Problemas de Dados](#2-problemas-de-dados)
3. [Problemas de Configura√ß√£o](#3-problemas-de-configura√ß√£o)
4. [Problemas de Infraestrutura](#4-problemas-de-infraestrutura)
5. [Debugging Avan√ßado](#5-debugging-avan√ßado)
6. [Problemas de Performance](#6-problemas-de-performance)
7. [Problemas com Versionamento](#7-problemas-com-versionamento)
8. [Health Checks e Testes](#8-health-checks-e-testes)
9. [Maintenance Window](#9-maintenance-window)
10. [Contatos e Escalation](#10-contatos-e-escalation)
11. [Checklist de Verifica√ß√£o](#11-checklist-de-verifica√ß√£o)
12. [Quick Reference - Comandos √öteis](#12-quick-reference---comandos-√∫teis)
13. [Escalation Path](#13-escalation-path)

---

## 1. Problemas de Execu√ß√£o

### 1.1 Pipeline N√£o Inicia

#### üîç Sintomas
```
[ERROR] DAG failed to parse
[ERROR] Task execution failed
[ERROR] SchedulerJob: Failed to start
```

#### üõ†Ô∏è Diagn√≥stico

**Passo 1:** Verificar logs do Scheduler
```bash
# Acessar logs do Airflow
docker-compose logs airflow-scheduler | tail -100

# Ou em desenvolvimento local
tail -f logs/scheduler/latest
```

**Passo 2:** Validar sintaxe da DAG
```bash
# Verificar se DAG est√° bem formada
python dags/bees_brewery_dag.py

# Verificar erros de import
python -m py_compile dags/bees_brewery_dag.py
```

**Passo 3:** Checar permiss√µes de arquivo
```bash
ls -la dags/bees_brewery_dag.py
# Deve estar com permiss√µes 644 ou 755
```

#### ‚úÖ Solu√ß√£o

**Cen√°rio A: Erro de Sintaxe Python**
```bash
# 1. Verificar erro espec√≠fico
python dags/bees_brewery_dag.py 2>&1 | grep -A 10 "SyntaxError"

# 2. Corrigir arquivo
# (Editar dags/bees_brewery_dag.py)

# 3. Revalidar
python dags/bees_brewery_dag.py
```

**Cen√°rio B: Erro de Import**
```bash
# 1. Verificar depend√™ncias instaladas
pip list | grep -E "airflow|pyspark|apache"

# 2. Instalar depend√™ncias faltantes
pip install -r requirements.txt

# 3. Reiniciar containers (se Docker)
docker-compose restart airflow-scheduler
```

**Cen√°rio C: Permiss√µes Incorretas**
```bash
# Corrigir permiss√µes
chmod 644 dags/bees_brewery_dag.py

# Reiniciar Airflow
docker-compose restart airflow-webserver airflow-scheduler
# OU
systemctl restart airflow-scheduler
```

#### üìù Verifica√ß√µes
- [ ] Arquivo `dags/bees_brewery_dag.py` existe
- [ ] Sintaxe Python v√°lida
- [ ] Todas as importa√ß√µes resolvem
- [ ] Permiss√µes de arquivo corretas (644)
- [ ] Scheduler est√° rodando

#### ‚è±Ô∏è SLA: 10 minutos

---

### 1.2 Task Execution Timeout

#### üîç Sintomas
```
[ERROR] Task timeout after 3600 seconds
[ERROR] Max tries exceeded: 3
[ERROR] Task heartbeat lost
```

#### üõ†Ô∏è Diagn√≥stico

**Passo 1:** Verificar logs da task
```bash
# Em Docker
docker-compose logs airflow-worker | grep "ingestion_bronze" | tail -50

# Em local
tail -f logs/dag_id=bees_brewery_medallion/task_id=ingestion_bronze/*.log
```

**Passo 2:** Checar uso de recursos
```bash
# CPU/Memory
docker stats airflow-worker

# OU em local
top -p <spark_pid>
free -m
```

**Passo 3:** Validar conectividade com API
```bash
# Testar endpoint da API
curl -I https://api.openbrewerydb.org/v1/breweries

# Com timeout customizado
curl --max-time 10 https://api.openbrewerydb.org/v1/breweries | head -20
```

#### ‚úÖ Solu√ß√£o

**Cen√°rio A: API Lenta**
```python
# Em config/environments/prod.yaml, aumentar timeout
api:
  timeout: 60  # De 30 para 60 segundos
  retries: 5
  backoff_factor: 2
```

**Cen√°rio B: Spark Lento**
```python
# Em config/environments/prod.yaml, aumentar recursos
spark:
  driver_memory: 4g    # De 2g para 4g
  executor_memory: 4g
  executor_cores: 4
```

**Cen√°rio C: Timeout da Task**
```python
# Em dags/bees_brewery_dag.py
ingestion_task = PythonOperator(
    task_id='ingestion_bronze',
    python_callable=run_ingestion,
    execution_timeout=timedelta(minutes=30),  # Aumentar de 10 para 30
    retries=3,
    retry_delay=timedelta(minutes=5),
)
```

**Cen√°rio D: Muitos Retries**
```bash
# Se h√° muitas tentativas falhando:
# 1. Limpar estado anterior
airflow tasks clear bees_brewery_medallion -s 2026-02-01

# 2. Reexecutar
airflow tasks run bees_brewery_medallion ingestion_bronze 2026-02-01
```

#### üìù Verifica√ß√µes
- [ ] Conectividade com API (curl test)
- [ ] Recursos dispon√≠veis (CPU/Memory)
- [ ] Timeout configurado adequadamente
- [ ] Rede est√°vel (sem packet loss)
- [ ] Logs indicam etapa de lentid√£o

#### ‚è±Ô∏è SLA: 20 minutos

---

### 1.3 Task Failed com AttributeError

#### üîç Sintomas
```
[ERROR] AttributeError: 'NoneType' object has no attribute 'baseRDD'
[ERROR] AttributeError: 'DataFrame' has no attribute 'transform'
```

#### üõ†Ô∏è Diagn√≥stico

**Passo 1:** Extrair full traceback
```bash
# Ver erro completo
docker-compose logs airflow-worker | grep -A 30 "AttributeError"

# OU em arquivo
cat logs/dag_id=bees_brewery_medallion/task_id=*/attempt=1/*.log | grep -A 30 "Traceback"
```

**Passo 2:** Verificar vers√£o de depend√™ncias
```bash
# Vers√£o do PySpark
python -c "import pyspark; print(pyspark.__version__)"

# Vers√£o do Airflow
python -c "import airflow; print(airflow.__version__)"

# Comparar com requirements.txt
cat requirements.txt | grep -E "pyspark|apache-airflow"
```

#### ‚úÖ Solu√ß√£o

**Cen√°rio A: Spark Session √© None**
```python
# ‚ùå ERRO
class IngestionJob(BaseJob):
    def execute(self):
        self.spark.createDataFrame(...)  # self.spark pode ser None

# ‚úÖ CORRETO
class IngestionJob(BaseJob):
    def execute(self):
        if self.spark is None:
            raise ValueError("Spark session n√£o foi inicializado")
        self.spark.createDataFrame(...)
```

**Cen√°rio B: Vers√£o PySpark Incompat√≠vel**
```bash
# 1. Verificar vers√£o esperada
cat requirements.txt | grep pyspark

# 2. Reinstalar vers√£o correta
pip install --force-reinstall pyspark==3.5.0

# 3. Validar
python -c "from pyspark.sql import SparkSession; print('OK')"
```

**Cen√°rio C: DataFrame n√£o tem m√©todo esperado**
```python
# ‚ùå ERRO - PySpark 3.0 n√£o tem 'transform'
df.transform(lambda x: x.select("*"))

# ‚úÖ CORRETO - Usar select direto
df.select("*")

# ‚úÖ OU - Para vers√£o nova (3.5+)
from pyspark.sql.functions import transform
```

#### üìù Verifica√ß√µes
- [ ] Vers√£o PySpark matches requirements.txt
- [ ] Spark Session inicializado corretamente
- [ ] M√©todos dispon√≠veis na vers√£o em uso
- [ ] Imports corretos para a vers√£o
- [ ] Sem conflitos de depend√™ncias

#### ‚è±Ô∏è SLA: 15 minutos

---

## 2. Problemas de Dados

### 2.1 Bronze Layer Vazia

#### üîç Sintomas
```
[WARNING] Bronze data est√° vazio!
[ERROR] Silver layer precisa de dados Bronze
[ERROR] ValueError: No schema provided
```

#### üõ†Ô∏è Diagn√≥stico

**Passo 1:** Verificar se dados foram salvos
```bash
# Verificar estrutura de diret√≥rios
find datalake/bronze -type f | head -20

# Verificar tamanho de dados
du -sh datalake/bronze/breweries/

# Contar arquivos
find datalake/bronze/breweries -name "*.json" -o -name "*.parquet" | wc -l
```

**Passo 2:** Validar logs de ingestion
```bash
# Extrair logs da task
cat logs/dag_id=bees_brewery_medallion/task_id=ingestion_bronze/*/log.txt

# Procurar por erros
grep -i "error\|exception\|failed" logs/dag_id=bees_brewery_medallion/task_id=ingestion_bronze/*/log.txt
```

**Passo 3:** Testar API manualmente
```bash
# Verificar se API est√° respondendo
curl -s "https://api.openbrewerydb.org/v1/breweries?per_page=1" | python -m json.tool

# Verificar quantidade de registros
curl -s "https://api.openbrewerydb.org/v1/breweries?per_page=1" | jq '.[] | length'
```

#### ‚úÖ Solu√ß√£o

**Cen√°rio A: API n√£o est√° respondendo**
```bash
# 1. Testar conectividade
ping -c 3 api.openbrewerydb.org

# 2. Testar DNS
nslookup api.openbrewerydb.org

# 3. Aguardar recupera√ß√£o da API
sleep 300  # Esperar 5 minutos

# 4. Reexecutar task
airflow tasks run bees_brewery_medallion ingestion_bronze 2026-02-01
```

**Cen√°rio B: Dados foram salvos em local errado**
```bash
# 1. Procurar por dados em outros locais
find datalake -name "*.json" -o -name "*.parquet"

# 2. Verificar configura√ß√£o de paths
cat config/environments/prod.yaml | grep -A 5 "storage:"

# 3. Mover dados para local correto
mv datalake/bronze_output/* datalake/bronze/breweries/

# 4. Reexecutar pipeline dependente
airflow tasks run bees_brewery_medallion transformation_silver 2026-02-01
```

**Cen√°rio C: Ingestion falhou silenciosamente**
```bash
# 1. Executar manualmente para ver erro
python -c "
from spark_jobs.ingestion import fetch_and_save_bronze
from core.spark_session import get_spark_session

spark = get_spark_session()
fetch_and_save_bronze(spark, 'https://api.openbrewerydb.org/v1/breweries', 'datalake/bronze/breweries')
"

# 2. Corrigir erro
# (verificar logs de erro acima)

# 3. Limpar e reexecutar
rm -rf datalake/bronze/breweries/*
airflow tasks run bees_brewery_medallion ingestion_bronze 2026-02-01
```

#### üìù Verifica√ß√µes
- [ ] API est√° respondendo (curl test)
- [ ] Conectividade com internet OK
- [ ] Caminho de output est√° correto
- [ ] Permiss√µes de escrita em datalake
- [ ] Logs mostram dados foram fetched

#### ‚è±Ô∏è SLA: 15 minutos

---

### 2.2 Schema Mismatch em Silver Layer

#### üîç Sintomas
```
[ERROR] Schema mismatch!
[ERROR] Expected StructType([...]), got StructType([...])
[ERROR] ValueError: Schema validation failed
```

#### üõ†Ô∏è Diagn√≥stico

**Passo 1:** Verificar schema esperado vs atual
```bash
# Extrair schema da primeira linha de Bronze
python -c "
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName('debug').getOrCreate()
df = spark.read.json('datalake/bronze/breweries/').limit(1)
df.printSchema()
"

# Comparar com schema esperado
cat schemas/bronze.py | grep -A 20 "BREWERIES_SCHEMA"
```

**Passo 2:** Verificar dados de entrada
```bash
# Ver sample de dados
cat datalake/bronze/breweries/*.json | head -5 | python -m json.tool

# Verificar campos presentes
cat datalake/bronze/breweries/*.json | jq 'keys' | head -1
```

#### ‚úÖ Solu√ß√£o

**Cen√°rio A: Campos faltando nos dados**
```bash
# 1. Verificar quais campos est√£o faltando
python -c "
import json
with open('datalake/bronze/breweries/*.json', 'r') as f:
    data = json.load(f)
    print('Campos presentes:', data.keys())
"

# 2. Se API n√£o retorna campo, adicionar logicamente
# Em spark_jobs/transformation_silver.py
from pyspark.sql.functions import lit

df = df.withColumn('campo_faltando', lit(None))
```

**Cen√°rio B: Tipo de dado diferente**
```bash
# 1. Verificar tipo esperado vs atual
python -c "
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName('debug').getOrCreate()
df = spark.read.json('datalake/bronze/breweries/').limit(1)

# Ver tipo de cada coluna
for field in df.schema:
    print(f'{field.name}: {field.dataType}')
"

# 2. Converter tipos conforme necess√°rio
# Em spark_jobs/transformation_silver.py
from pyspark.sql.types import StringType, IntegerType
from pyspark.sql.functions import col

df = df.withColumn('id', col('id').cast(StringType()))
```

**Cen√°rio C: Schema definido incorretamente**
```bash
# 1. Atualizar schema em schemas/bronze.py
# Remover campos faltando ou adicionar novos

# 2. Validar schema
python -c "
from schemas.bronze import BronzeSchema
print('Schema BREWERIES:')
BronzeSchema.BREWERIES_SCHEMA.printTreeString()
"

# 3. Reexecutar pipeline
airflow tasks run bees_brewery_medallion transformation_silver 2026-02-01
```

#### üìù Verifica√ß√µes
- [ ] Campos de Bronze match com esperado
- [ ] Tipos de dados corretos
- [ ] Schema em `schemas/bronze.py` atualizado
- [ ] Sem valores inesperados (null onde n√£o esperado)
- [ ] Dados de amostra validam com schema

#### ‚è±Ô∏è SLA: 20 minutos

---

### 2.3 Gold Layer com Resultados Incorretos

#### üîç Sintomas
```
[WARNING] Resultado diferente do esperado
[ERROR] Somas n√£o batem com manual check
[ERROR] Contagens incorretas por estado
```

#### üõ†Ô∏è Diagn√≥stico

**Passo 1:** Validar dados de entrada (Silver)
```bash
# Contar registros
python -c "
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName('debug').getOrCreate()
silver = spark.read.parquet('datalake/silver/breweries/')
print(f'Total de breweries em Silver: {silver.count()}')
print(f'Sem duplicatas: {silver.dropDuplicates().count()}')
"
```

**Passo 2:** Validar l√≥gica de agrega√ß√£o
```bash
# Executar query de agrega√ß√£o manualmente
python -c "
from pyspark.sql import SparkSession
from pyspark.sql.functions import count

spark = SparkSession.builder.appName('debug').getOrCreate()
silver = spark.read.parquet('datalake/silver/breweries/')

# Agrega√ß√£o por tipo e estado
agg_result = silver.groupBy('brewery_type', 'state_province').count().collect()
for row in agg_result[:10]:
    print(row)
"
```

**Passo 3:** Comparar com expectativa
```bash
# Verificar resultado Gold
python -c "
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName('debug').getOrCreate()
gold = spark.read.parquet('datalake/gold/breweries_agg/')
gold.show(20)

# Exportar para an√°lise
gold.coalesce(1).write.mode('overwrite').csv('/tmp/gold_debug/')
"
```

#### ‚úÖ Solu√ß√£o

**Cen√°rio A: Duplicatas n√£o foram removidas**
```python
# ‚úÖ CORRETO - Em transformation_silver.py
from pyspark.sql.functions import row_number, col
from pyspark.sql.window import Window

window_spec = Window.partitionBy("id").orderBy("updated_at")
df = df.withColumn("rn", row_number().over(window_spec))
df = df.filter(col("rn") == 1).drop("rn")
```

**Cen√°rio B: Agrega√ß√£o com valores NULL**
```python
# ‚úÖ CORRETO - Em aggregation_gold.py
from pyspark.sql.functions import count, coalesce, lit

result = silver.filter(col("brewery_type").isNotNull()) \
    .groupBy("brewery_type", "state_province") \
    .agg(count("*").alias("quantity"))
```

**Cen√°rio C: Particionamento incorreto**
```python
# ‚úÖ CORRETO - Verificar particionamento
silver.show()  # Verificar colunas
silver.groupBy("state_province").count().show()  # Contar por estado

# Se estado est√° vazio/null:
silver.filter(col("state_province").isNotNull()).groupBy("state_province").count().show()
```

#### üìù Verifica√ß√µes
- [ ] Silver cont√©m dados esperados
- [ ] Sem valores NULL onde n√£o esperado
- [ ] Agrega√ß√£o agrupa corretamente
- [ ] Contagens batem com valida√ß√£o manual
- [ ] Particionamento aplicado corretamente

#### ‚è±Ô∏è SLA: 25 minutos

---

## 3. Problemas de Configura√ß√£o

### 3.1 Arquivo Config N√£o Encontrado

#### üîç Sintomas
```
[ERROR] FileNotFoundError: config/environments/prod.yaml not found
[ERROR] KeyError: 'spark' not found in config
```

#### üõ†Ô∏è Diagn√≥stico

**Passo 1:** Verificar estrutura de configs
```bash
# Listar arquivos
find config -type f

# Verificar conte√∫do
cat config/config.py
cat config/environments/prod.yaml
```

**Passo 2:** Validar YAML syntax
```bash
# Verificar sintaxe YAML
python -c "import yaml; yaml.safe_load(open('config/environments/prod.yaml'))" || echo "YAML inv√°lido"

# Ver estrutura
python -c "import yaml; print(yaml.safe_load(open('config/environments/prod.yaml')))"
```

#### ‚úÖ Solu√ß√£o

**Cen√°rio A: Arquivo n√£o existe**
```bash
# 1. Criar arquivo base
cp config/environments/dev.yaml config/environments/prod.yaml

# 2. Ajustar para produ√ß√£o
# (Editar valores conforme necess√°rio)

# 3. Validar
python -c "from config.config import Config; c = Config.from_yaml('prod'); print('OK')"
```

**Cen√°rio B: Caminho relativo incorreto**
```python
# ‚ùå ERRO
config = Config.from_yaml("config/environments/prod.yaml")

# ‚úÖ CORRETO - Usar caminho relativo ao projeto
import os
config_path = os.path.join(os.path.dirname(__file__), "config", "environments", "prod.yaml")
config = Config.from_yaml(config_path)

# ‚úÖ OU - Em vari√°vel de ambiente
import os
env = os.getenv("ENV", "dev")
config = Config.from_yaml(f"config/environments/{env}.yaml")
```

**Cen√°rio C: Vari√°vel de ambiente n√£o setada**
```bash
# 1. Verificar vari√°vel
echo $ENV

# 2. Setar vari√°vel
export ENV=prod

# 3. Verificar que foi setada
echo $ENV

# 4. Em Docker, adicionar ao docker-compose.yaml
environment:
  - ENV=prod
  - PYTHONPATH=/opt/airflow
```

#### üìù Verifica√ß√µes
- [ ] Arquivo config existe em caminho esperado
- [ ] Sintaxe YAML v√°lida
- [ ] Vari√°veis de ambiente setadas
- [ ] Permiss√µes de leitura do arquivo (644)
- [ ] PYTHONPATH inclui diret√≥rio de configs

#### ‚è±Ô∏è SLA: 10 minutos

---

### 3.2 Credenciais/API Key N√£o Configurada

#### üîç Sintomas
```
[ERROR] InvalidCredentialsError
[ERROR] 401 Unauthorized
[ERROR] API key not provided
```

#### üõ†Ô∏è Diagn√≥stico

**Passo 1:** Verificar vari√°veis de ambiente
```bash
# Listar todas as vari√°veis relevantes
env | grep -i "api\|key\|secret\|password"

# Verificar vari√°vel espec√≠fica
echo $API_KEY
echo $OPENBREWERY_API_KEY
```

**Passo 2:** Verificar onde credenciais s√£o usadas
```bash
# Procurar por refer√™ncias
grep -r "API_KEY\|api_key\|secret" config/ spark_jobs/ --include="*.py"
```

#### ‚úÖ Solu√ß√£o

**Cen√°rio A: Vari√°vel n√£o est√° setada**
```bash
# 1. Setar temporariamente (dev only)
export API_KEY="sua_chave_aqui"

# 2. Verificar
echo $API_KEY

# 3. Permanentemente em ~/.bashrc ou ~/.zshrc
echo 'export API_KEY="sua_chave_aqui"' >> ~/.zshrc
source ~/.zshrc
```

**Cen√°rio B: Credenciais em arquivo**
```bash
# 1. Criar arquivo .env (N√ÉO COMMITAR)
echo "API_KEY=sua_chave_aqui" > .env

# 2. Carregar em script
set -a
source .env
set +a

# 3. Usar em Python
import os
api_key = os.getenv("API_KEY")
```

**Cen√°rio C: Credenciais em Docker**
```yaml
# docker-compose.yaml
services:
  airflow-worker:
    environment:
      - API_KEY=${API_KEY}
      - OPENBREWERY_API_KEY=${OPENBREWERY_API_KEY}
```

```bash
# Executar com vari√°veis
API_KEY="chave123" docker-compose up -d
```

#### üìù Verifica√ß√µes
- [ ] Vari√°vel de ambiente est√° setada
- [ ] Credenciais corretas
- [ ] Sem credenciais em c√≥digo ou git
- [ ] .env est√° em .gitignore
- [ ] Acesso √† API funciona (curl test)

#### ‚è±Ô∏è SLA: 10 minutos

---

## 4. Problemas de Infraestrutura

### 4.1 Docker Container N√£o Inicia

#### üîç Sintomas
```
[ERROR] Container exited with code 1
[ERROR] No space left on device
[ERROR] Cannot connect to Docker daemon
```

#### üõ†Ô∏è Diagn√≥stico

**Passo 1:** Verificar status dos containers
```bash
# Ver containers rodando
docker-compose ps

# Ver todos containers (incluindo parados)
docker-compose ps -a

# Ver logs de container espec√≠fico
docker-compose logs airflow-worker | tail -50
```

**Passo 2:** Verificar recursos
```bash
# Uso de disco
docker system df

# Recursos em tempo real
docker stats

# Espa√ßo dispon√≠vel
df -h
```

**Passo 3:** Validar arquivo docker-compose
```bash
# Validar sintaxe
docker-compose config

# Ver se h√° erros
docker-compose config 2>&1 | head -20
```

#### ‚úÖ Solu√ß√£o

**Cen√°rio A: Sem espa√ßo em disco**
```bash
# 1. Liberar espa√ßo
docker system prune -a  # Remove containers e images n√£o usadas
docker volume prune     # Remove volumes n√£o usados

# 2. Limpar espec√≠ficos
docker rmi $(docker images -q)  # Remove todas as images
docker volume rm $(docker volume ls -q)  # Remove todos os volumes

# 3. Reiniciar
docker-compose up -d
```

**Cen√°rio B: Docker daemon n√£o est√° rodando**
```bash
# macOS
brew services start docker
# OU
open /Applications/Docker.app

# Linux
sudo systemctl start docker

# Verificar
docker --version
```

**Cen√°rio C: Port j√° em uso**
```bash
# 1. Verificar qual processo usa a port
lsof -i :8080  # Para porta 8080

# 2. Liberar port
kill -9 <PID>

# 3. OU usar port diferente em docker-compose.yaml
ports:
  - "8081:8080"  # Usar 8081 ao inv√©s de 8080
```

**Cen√°rio D: Arquivo docker-compose corrompido**
```bash
# 1. Validar
docker-compose config

# 2. Se houver erro, corrigir indenta√ß√£o/sintaxe
# (Editar docker-compose.yaml)

# 3. Tentar novamente
docker-compose up -d
```

#### üìù Verifica√ß√µes
- [ ] Docker daemon est√° rodando
- [ ] Espa√ßo em disco dispon√≠vel (>10GB)
- [ ] Ports n√£o est√£o em uso
- [ ] docker-compose.yaml √© v√°lido
- [ ] Permiss√µes de arquivo OK

#### ‚è±Ô∏è SLA: 15 minutos

---

### 4.2 Spark Job OutOfMemoryError

#### üîç Sintomas
```
[ERROR] Exception in thread "Executor task launch worker"
[ERROR] java.lang.OutOfMemoryError: GC overhead limit exceeded
[ERROR] java.lang.OutOfMemoryError: Java heap space
```

#### üõ†Ô∏è Diagn√≥stico

**Passo 1:** Verificar mem√≥ria atual
```bash
# Em Docker
docker stats airflow-worker

# Em local
free -h
ps aux | grep spark | grep java
```

**Passo 2:** Verificar configura√ß√£o de mem√≥ria
```bash
# Ver configura√ß√£o Spark
cat config/environments/prod.yaml | grep -A 10 "spark:"

# Ver argumentos JVM
grep -r "Xmx\|Xms\|executor_memory\|driver_memory" config/
```

#### ‚úÖ Solu√ß√£o

**Cen√°rio A: Memory insuficiente**
```yaml
# config/environments/prod.yaml
spark:
  driver_memory: 4g      # Aumentar de 2g
  executor_memory: 8g    # Aumentar de 4g
  executor_cores: 4
  num_executors: 2       # Ou reduzir para 1 se pouco RAM
```

**Cen√°rio B: Em Docker, limitar melhor**
```yaml
# docker-compose.yaml
services:
  airflow-worker:
    environment:
      - SPARK_LOCAL_IP=0.0.0.0
      - SPARK_DRIVER_MEMORY=4g
      - SPARK_EXECUTOR_MEMORY=4g
    mem_limit: 16g  # Limitar container
```

**Cen√°rio C: Dados muito grandes**
```python
# Adicionar reparticionamento em ingestion
# spark_jobs/ingestion.py

df = spark.read.json(...)
# Reparti√ß√£o antes de salvar
df = df.repartition(10)  # Dividir em 10 parti√ß√µes
df.write.mode("overwrite").json(output_path)
```

**Cen√°rio D: Validar m√°quina tem recursos**
```bash
# Verificar RAM dispon√≠vel
free -h

# Se < 8GB, n√£o rodar em local
# Se < 4GB, deve usar Docker com limites reduzidos

# Recomenda√ß√£o
# Desenvolvimento: 4GB RAM no container
# Produ√ß√£o: 16GB+ RAM no container
```

#### üìù Verifica√ß√µes
- [ ] RAM dispon√≠vel na m√°quina
- [ ] Configura√ß√£o Spark mem√≥ria adequada
- [ ] Sem outras aplica√ß√µes consumindo RAM
- [ ] Reparticionamento aplicado se necess√°rio
- [ ] Persist√™ncia de dados n√£o explosiva

#### ‚è±Ô∏è SLA: 20 minutos

---

## 5. Debugging Avan√ßado

### 5.1 Ativar Debug Logging

#### üõ†Ô∏è Procedimento

**Passo 1:** Configurar logging em dev
```yaml
# config/environments/dev.yaml
logging:
  level: DEBUG
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
```

**Passo 2:** Adicionar logging em c√≥digo
```python
# spark_jobs/ingestion.py
import logging

logger = logging.getLogger(__name__)

class IngestionJob(BaseJob):
    def execute(self):
        logger.debug(f"Input path: {self.input_path}")
        logger.info(f"Starting ingestion...")
        logger.debug(f"API URL: {self.api_url}")
        
        try:
            df = self._fetch_data()
            logger.debug(f"Fetched {df.count()} records")
        except Exception as e:
            logger.error(f"Error fetching data: {str(e)}", exc_info=True)
            raise
```

**Passo 3:** Ver logs detalhados
```bash
# Em Docker
docker-compose logs airflow-worker | grep DEBUG

# Em arquivo
tail -f logs/dag_id=bees_brewery_medallion/task_id=*/attempt=*/log.txt | grep DEBUG
```

---

### 5.2 Executar Task Isolada

#### üõ†Ô∏è Procedimento

**Passo 1:** Executar via Python direto
```python
# script_debug.py
import sys
sys.path.insert(0, '/path/to/project')

from config.config import Config
from core.storage import LocalStorage
from spark_jobs.ingestion import IngestionJob

# Carregar config
config = Config.from_yaml("config/environments/dev.yaml")

# Criar job
storage = LocalStorage(config.storage.path)
job = IngestionJob(config.to_dict(), storage)

# Executar
try:
    job.execute()
    print("‚úÖ Job succeeded!")
except Exception as e:
    print(f"‚ùå Job failed: {str(e)}")
    import traceback
    traceback.print_exc()
```

```bash
python script_debug.py
```

**Passo 2:** Debugar com breakpoints (VSCode)
```json
// .vscode/launch.json
{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Debug Ingestion",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/script_debug.py",
            "console": "integratedTerminal",
            "justMyCode": false
        }
    ]
}
```

---

### 5.3 Inspecionar DataFrame

#### üõ†Ô∏è Procedimento

```python
# script_inspect.py
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, isnull, count

spark = SparkSession.builder.appName("inspect").getOrCreate()

# Ler dados
df = spark.read.json("datalake/bronze/breweries/")

print("=== SCHEMA ===")
df.printSchema()

print("\n=== SAMPLE DATA ===")
df.show(5, truncate=False)

print("\n=== COUNT ===")
print(f"Total records: {df.count()}")

print("\n=== NULL VALUES ===")
for col_name in df.columns:
    null_count = df.filter(isnull(col(col_name))).count()
    print(f"{col_name}: {null_count} nulls")

print("\n=== DISTINCT VALUES ===")
for col_name in df.columns[:3]:  # Primeiras 3 colunas
    distinct = df.select(col_name).distinct().count()
    print(f"{col_name}: {distinct} distinct values")

print("\n=== SUMMARY ===")
df.describe().show()
```

```bash
python script_inspect.py
```

---

## 6. Problemas de Performance

### 6.1 Pipeline Muito Lento

#### üîç Sintomas
```
[WARNING] Pipeline rodando h√° mais de 2 horas
[WARNING] Bronze task leva 40 minutos
[WARNING] Silver transformation timeout
```

#### üõ†Ô∏è Diagn√≥stico

**Passo 1:** Identificar gargalo
```bash
# Ver tempo de cada task
airflow dags test bees_brewery_medallion 2026-02-01 -d | grep "Task duration"

# OU em logs
cat logs/dag_id=bees_brewery_medallion/*/log.txt | grep -E "finished|duration"
```

**Passo 2:** Monitorar recursos durante execu√ß√£o
```bash
# Terminal 1: Executar pipeline
airflow tasks run bees_brewery_medallion ingestion_bronze 2026-02-01

# Terminal 2: Monitorar (em Docker)
watch -n 1 'docker stats airflow-worker --no-stream | grep -E "CPU|MEM"'

# OU em local
watch -n 1 'ps aux | grep spark | grep -v grep'
```

**Passo 3:** Analisar plano de execu√ß√£o Spark
```python
# script_analyze_plan.py
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("analyze").getOrCreate()
df = spark.read.json("datalake/bronze/breweries/")

# Ver plano de execu√ß√£o
df.explain(extended=True)

# Contar parti√ß√µes
print(f"Parti√ß√µes: {df.rdd.getNumPartitions()}")

# Ver distribui√ß√£o de dados
df.groupBy("state_province").count().show(20)
```

#### ‚úÖ Solu√ß√£o

**Cen√°rio A: Muitas parti√ß√µes causa overhead**
```python
# spark_jobs/ingestion.py
df = spark.read.json(...)
# Reduzir parti√ß√µes
df = df.coalesce(4)  # De 200 para 4
df.write.mode("overwrite").json(output_path)
```

**Cen√°rio B: Falta de broadcast em join**
```python
# ‚úÖ CORRETO - Bronze √© grande, refer√™ncia √© pequena
from pyspark.sql.functions import broadcast

result = bronze.join(
    broadcast(reference_df),  # Enviar pequeno DF para todos os nodes
    "id"
)
```

**Cen√°rio C: Sem cache de dados intermedi√°rios**
```python
# ‚úÖ CORRETO - Cache dados que ser√£o reutilizados
silver = bronze.filter(...).select(...)
silver.cache()

# Usar silver m√∫ltiplas vezes sem recalcular
silver.write.parquet(...)
```

**Cen√°rio D: API rate limit**
```python
# ‚úÖ CORRETO - Adicionar delays entre requisi√ß√µes
import time

for page in range(total_pages):
    data = fetch_page(page)
    time.sleep(0.5)  # 500ms entre requests
    df = df.union(convert_to_df(data))
```

#### üìù Verifica√ß√µes
- [ ] N√∫mero de parti√ß√µes apropriado (CPU count)
- [ ] Broadcast usado para DataFrames pequenos
- [ ] Cache aplicado em transforma√ß√µes reutilizadas
- [ ] Sem full table scans desnecess√°rios
- [ ] API rate limits respeitados

#### ‚è±Ô∏è SLA: 30 minutos

---

### 6.2 Consumo Excessivo de Mem√≥ria

#### üîç Sintomas
```
[ERROR] GC overhead limit exceeded
[ERROR] Unable to acquire memory
[WARNING] Spilling to disk
```

#### üõ†Ô∏è Diagn√≥stico

**Passo 1:** Verificar aloca√ß√£o atual
```bash
# Em Docker
docker stats --no-stream | grep airflow-worker

# Ver limites
docker inspect <container_id> | grep -A 5 "Memory"
```

**Passo 2:** Identificar opera√ß√µes memory-hungry
```python
# Verificar se h√° collect() em DF grande
# ‚ùå EVITAR
df.collect()  # Traz tudo para mem√≥ria

# ‚úÖ PREFERIR
df.show(5)     # Mostra amostra
df.count()     # Conta sem material
```

**Passo 3:** Monitorar durante execu√ß√£o
```bash
# Terminal separado
watch -n 1 'free -m; echo "---"; docker stats --no-stream'
```

#### ‚úÖ Solu√ß√£o

**Cen√°rio A: Collect em DataFrame grande**
```python
# ‚ùå ERRO
result = silver.groupBy("state").count().collect()
for row in result:
    process(row)

# ‚úÖ CORRETO - Usar iterate ou write
silver.groupBy("state").count().write.csv("/tmp/result/")

# ‚úÖ OU - Usar toLocalIterator()
for row in silver.groupBy("state").count().toLocalIterator():
    process(row)
```

**Cen√°rio B: Aumentar mem√≥ria alocada**
```yaml
# config/environments/prod.yaml
spark:
  driver_memory: 8g      # De 4g para 8g
  executor_memory: 8g    # De 4g para 8g
  executor_cores: 2      # Reduzir cores para menos tasks paralelas
  num_executors: 1       # Usar apenas 1 executor se tiver pouca RAM
```

**Cen√°rio C: Persist√™ncia intermedi√°ria**
```python
# spark_jobs/transformation_silver.py
# Dividir em etapas e salvar intermedi√°rios

# Etapa 1: Limpar dados
bronze = spark.read.json(...)
cleaned = bronze.filter(...).select(...)
cleaned.write.parquet("datalake/silver/tmp_cleaned/")

# Etapa 2: Transformar
cleaned = spark.read.parquet("datalake/silver/tmp_cleaned/")
transformed = cleaned.join(...).groupBy(...)
transformed.write.parquet("datalake/silver/breweries/")
```

#### üìù Verifica√ß√µes
- [ ] Sem collect() em DataFrames grandes
- [ ] Mem√≥ria alocada > tamanho maior DF √ó 3
- [ ] Persistent cache removido ap√≥s uso
- [ ] Etapas divididas se muito grandes
- [ ] Monitoramento durante execu√ß√£o

#### ‚è±Ô∏è SLA: 25 minutos

---

## 7. Problemas com Versionamento

### 7.1 DAG Alterada mas N√£o Reflete no Airflow

#### üîç Sintomas
```
[ERROR] Altera√ß√µes em bees_brewery_dag.py n√£o aparecem
[WARNING] Task ainda usa c√≥digo antigo
[ERROR] Mudan√ßas foram commitadas mas n√£o rodaram
```

#### üõ†Ô∏è Diagn√≥stico

**Passo 1:** Verificar se arquivo foi modificado
```bash
# Ver status Git
git status dags/bees_brewery_dag.py

# Ver √∫ltimo commit
git log -1 --oneline dags/bees_brewery_dag.py

# Ver diferen√ßas
git diff dags/bees_brewery_dag.py
```

**Passo 2:** Verificar parsing da DAG
```bash
# Validar sintaxe
python dags/bees_brewery_dag.py

# Ver quando foi parsed por √∫ltimo
ls -la logs/dag_processor_manager/
tail -50 logs/dag_processor_manager/dag_processor_manager.log | grep "bees_brewery_dag"
```

**Passo 3:** Verificar cache do Airflow
```bash
# Ver vers√£o em DB
docker-compose exec airflow-webserver airflow dags list | grep bees_brewery

# Ver arquivos em AIRFLOW_HOME
docker-compose exec airflow-webserver ls -la $AIRFLOW_HOME/dags/
```

#### ‚úÖ Solu√ß√£o

**Cen√°rio A: Arquivo n√£o foi salvo**
```bash
# Verificar conte√∫do
cat dags/bees_brewery_dag.py | grep -A 5 "dag_id="

# Se vazio ou incorreto, editar novamente
# (Usar editor de prefer√™ncia)
```

**Cen√°rio B: Dag parser n√£o recarregou**
```bash
# Em Docker
docker-compose restart airflow-scheduler

# Em local
systemctl restart airflow-scheduler

# Aguardar parse (at√© 5 minutos)
sleep 60
airflow dags list | grep bees_brewery
```

**Cen√°rio C: Cache do browser**
```bash
# Hard refresh em Airflow UI
# Cmd+Shift+R (Mac) ou Ctrl+Shift+R (Linux/Windows)

# OU limpar via terminal
curl -X POST http://localhost:8080/api/experimental/pools/clear_cache
```

**Cen√°rio D: For√ßar reparse**
```bash
# 1. Limpar DAG do DB
airflow dags delete bees_brewery_medallion

# 2. Recriar desde zero
airflow dags list  # Vai ler arquivo novamente

# 3. Reexecutar
airflow dags trigger bees_brewery_medallion
```

#### üìù Verifica√ß√µes
- [ ] Arquivo editado e salvo corretamente
- [ ] Git status mostra arquivo modificado
- [ ] Scheduler foi reiniciado ap√≥s mudan√ßa
- [ ] Browser cache foi limpo (hard refresh)
- [ ] DAG parser completou (check logs)

#### ‚è±Ô∏è SLA: 15 minutos

---

### 7.2 Merge Conflict em DAG ou Configura√ß√£o

#### üîç Sintomas
```
[ERROR] CONFLICT (content conflict): dags/bees_brewery_dag.py
[ERROR] Automatic merge failed
[ERROR] Fix conflicts and commit the result
```

#### üõ†Ô∏è Diagn√≥stico

**Passo 1:** Identificar arquivos em conflito
```bash
# Ver status
git status

# Ver conflitos detalhados
git diff --name-only --diff-filter=U
```

**Passo 2:** Ver marcadores de conflito
```bash
# Abrir arquivo
cat dags/bees_brewery_dag.py | grep -A 5 -B 5 "<<<<"

# Mostrar ambos os lados
git diff dags/bees_brewery_dag.py
```

#### ‚úÖ Solu√ß√£o

**Cen√°rio A: Resolver conflito manualmente**
```bash
# 1. Abrir arquivo e resolver conflito
# Remover marcadores: <<<<<<, ======, >>>>>>
# Manter c√≥digo correto de ambos os lados

# 2. Validar resultado
python dags/bees_brewery_dag.py

# 3. Marcar como resolvido
git add dags/bees_brewery_dag.py

# 4. Completar merge
git commit -m "Merge: Resolve conflicts in DAG"
```

**Cen√°rio B: Usar vers√£o do branch atual**
```bash
# Manter vers√£o local (--ours)
git checkout --ours dags/bees_brewery_dag.py
git add dags/bees_brewery_dag.py

# OU manter vers√£o remota (--theirs)
git checkout --theirs dags/bees_brewery_dag.py
git add dags/bees_brewery_dag.py
```

**Cen√°rio C: Abort merge e come√ßar novamente**
```bash
# Se tudo ficou muito confuso
git merge --abort

# Tentar merge novamente
git merge origin/main
```

#### üìù Verifica√ß√µes
- [ ] Ambos os lados do conflito entendidos
- [ ] C√≥digo merged √© v√°lido (python -m py_compile)
- [ ] Testes passam ap√≥s merge
- [ ] Commit message descreve resolu√ß√£o
- [ ] Nenhum marcador de conflito permanece

#### ‚è±Ô∏è SLA: 20 minutos

---

## 8. Health Checks e Testes

### 8.1 Executar Health Check do Pipeline

#### üõ†Ô∏è Procedimento

```bash
# script_health_check.sh
#!/bin/bash

echo "üè• HEALTH CHECK - BEES Brewery Pipeline"
echo "========================================"

# 1. Verificar Docker
echo -e "\n‚úì Verificando Docker..."
if docker-compose ps | grep -q "Up"; then
    echo "  ‚úÖ Docker containers rodando"
else
    echo "  ‚ùå Docker containers n√£o est√£o todos UP"
    docker-compose ps
fi

# 2. Verificar Airflow
echo -e "\n‚úì Verificando Airflow..."
if curl -s http://localhost:8080/api/v1/dags | jq '.dags[0]' > /dev/null; then
    echo "  ‚úÖ Airflow webserver respondendo"
else
    echo "  ‚ùå Airflow n√£o est√° respondendo"
fi

# 3. Verificar API
echo -e "\n‚úì Verificando Open Brewery DB..."
if curl -s -I https://api.openbrewerydb.org/v1/breweries | grep -q "200"; then
    echo "  ‚úÖ API respondendo com 200 OK"
else
    echo "  ‚ùå API n√£o est√° respondendo"
fi

# 4. Verificar Spark
echo -e "\n‚úì Verificando Spark..."
if python -c "from pyspark.sql import SparkSession; print('OK')" 2>/dev/null; then
    echo "  ‚úÖ PySpark instalado corretamente"
else
    echo "  ‚ùå Problema com PySpark"
fi

# 5. Verificar Dados
echo -e "\n‚úì Verificando Data Lake..."
BRONZE_COUNT=$(find datalake/bronze -type f | wc -l)
if [ "$BRONZE_COUNT" -gt 0 ]; then
    echo "  ‚úÖ Bronze layer: $BRONZE_COUNT arquivos"
else
    echo "  ‚ö†Ô∏è  Bronze layer vazio"
fi

echo -e "\n‚úÖ Health Check Conclu√≠do!"
```

```bash
chmod +x script_health_check.sh
./script_health_check.sh
```

---

### 8.2 Executar Testes Unit√°rios

#### üõ†Ô∏è Procedimento

```bash
# Executar todos os testes
pytest tests/ -v

# Executar teste espec√≠fico
pytest tests/test_ingestion.py -v

# Ver coverage
pytest tests/ --cov=spark_jobs --cov=core

# Gerar relat√≥rio HTML
pytest tests/ --cov=spark_jobs --cov-report=html
open htmlcov/index.html
```

---

## 9. Maintenance Window

### 9.1 Rotina de Limpeza Semanal

#### üõ†Ô∏è Checklist

```bash
# Rodar toda segunda-feira √†s 2am

# 1. Limpar logs antigos (>30 dias)
find logs -type f -mtime +30 -delete

# 2. Compactar logs
gzip logs/**/*.log

# 3. Limpar dados de teste
rm -rf datalake/tmp/*

# 4. Validar integridade
python tests/test_architecture.py

# 5. Backup de dados
tar -czf datalake_$(date +%Y%m%d).tar.gz datalake/

# 6. Reiniciar containers
docker-compose restart

# 7. Validar startup
sleep 60
./script_health_check.sh
```

---

### 9.2 Rotina de Atualiza√ß√µes Mensais

#### üõ†Ô∏è Checklist

```bash
# Executar todo primeiro dia do m√™s

# 1. Atualizar depend√™ncias
pip install --upgrade -r requirements.txt

# 2. Rodar testes
pytest tests/ -v

# 3. Rodar full pipeline
airflow dags backfill bees_brewery_medallion --start-date 2026-01-01 --end-date 2026-02-01

# 4. Validar sa√≠das
python scripts/validate_outputs.py

# 5. Atualizar documenta√ß√£o
# (Revisar RUNBOOK_TROUBLESHOOTING.md, etc)

# 6. Commit changes
git add requirements.txt docs/
git commit -m "Monthly update: $(date +%B-%Y)"
git push
```

---

## 10. Contatos e Escalation

### 10.1 Matriz de Responsabilidades

| Categoria | Respons√°vel | Contato | Tempo Resposta |
|-----------|------------|---------|----------------|
| Pipeline Airflow | Data Engineer #1 | email@company.com | 1h |
| Spark/Data | Data Engineer #2 | email2@company.com | 2h |
| Infraestrutura | DevOps | devops@company.com | 30min |
| Banco de Dados | DBA | dba@company.com | 1h |
| On-Call Rotativo | Verificar PagerDuty | - | 15min |

### 10.2 Escalation Flow

```
N√≠vel 1: Consultara runbook (voc√™ aqui)
   ‚Üì
N√≠vel 2: Contatar Data Engineer respons√°vel
   ‚Üì
N√≠vel 3: Engajar DevOps/Infraestrutura
   ‚Üì
N√≠vel 4: Engajar On-Call Engineer
   ‚Üì
N√≠vel 5: Engajar Tech Lead / CTO
```

---

## 11. Checklist de Verifica√ß√£o

### 11.1 Antes de Rodar Pipeline

- [ ] **Configura√ß√£o**
  - [ ] `config/environments/prod.yaml` existe e √© v√°lido
  - [ ] Vari√°veis de ambiente setadas (`$ENV`, `$API_KEY`)
  - [ ] PYTHONPATH inclui diret√≥rio do projeto

- [ ] **C√≥digo**
  - [ ] Sem erros de syntax (`python -m py_compile`)
  - [ ] Imports resolvem (`python -c "from dags import bees_brewery_dag"`)
  - [ ] Testes passando (`pytest tests/ -v`)

- [ ] **Infraestrutura**
  - [ ] Docker daemon rodando
  - [ ] Espa√ßo em disco dispon√≠vel (>10GB)
  - [ ] Mem√≥ria dispon√≠vel (>4GB)
  - [ ] Ports livres (8080, 5432, 6379)

- [ ] **Conectividade**
  - [ ] Internet funcionando
  - [ ] API acess√≠vel (`curl -I https://api.openbrewerydb.org/v1/breweries`)
  - [ ] DNS resolvendo (`nslookup api.openbrewerydb.org`)

- [ ] **Dados**
  - [ ] Diret√≥rio `datalake` existe
  - [ ] Permiss√µes de escrita OK
  - [ ] Bronze/Silver/Gold directories criados

### 11.2 Ap√≥s Falha de Pipeline

1. **Coletar Informa√ß√µes**
   - [ ] Screenshot da mensagem de erro
   - [ ] Logs completos da task
   - [ ] Vers√£o do software (`airflow --version`, `spark-submit --version`)
   - [ ] Status de recursos (CPU, memory, disk)

2. **Isolar Problema**
   - [ ] Reproduzir erro manualmente
   - [ ] Verificar logs com DEBUG ativado
   - [ ] Validar cada etapa da DAG isoladamente

3. **Documentar Solu√ß√£o**
   - [ ] Descrever erro exato
   - [ ] Listar passos de resolu√ß√£o
   - [ ] Adicionar ao POST_MORTEM se for novo erro

---

## 12. Quick Reference - Comandos √öteis

### Docker
```bash
# Containers
docker-compose up -d              # Iniciar
docker-compose down               # Parar
docker-compose logs -f            # Logs em tempo real
docker-compose ps                 # Status
docker exec -it <container> bash  # Entrar no container

# Limpeza
docker system prune -a            # Remove tudo n√£o usado
docker volume prune               # Remove volumes
```

### Airflow
```bash
# DAG
airflow dags list                 # Listar DAGs
airflow tasks list bees_brewery_medallion  # Listar tasks
airflow tasks run bees_brewery_medallion ingestion_bronze 2026-02-01  # Executar task

# Limpeza
airflow tasks clear bees_brewery_medallion -s 2026-02-01  # Limpar estado
airflow dags delete bees_brewery_medallion  # Deletar DAG
```

### Spark
```bash
# Local
spark-submit --version           # Vers√£o
spark-shell                      # REPL Scala
pyspark                          # REPL Python

# Em Docker
docker-compose exec airflow-worker spark-submit --version
docker-compose exec airflow-worker pyspark
```

### Data Lake
```bash
# Inspecionar
find datalake -type f | wc -l    # Contar arquivos
du -sh datalake/                 # Tamanho total
ls -lah datalake/bronze/breweries/

# Limpeza
rm -rf datalake/bronze/*         # Limpar Bronze
rm -rf datalake/silver/*         # Limpar Silver
rm -rf datalake/gold/*           # Limpar Gold
```

### Git
```bash
# Status
git status                        # Ver mudan√ßas
git log --oneline -10            # √öltimos 10 commits
git diff                         # Diferen√ßas n√£o staged

# Opera√ß√µes
git pull origin main             # Atualizar do remoto
git push origin main             # Enviar para remoto
git stash                        # Guardar mudan√ßas temporariamente
```

---

## 13. Escalation Path

Se problema n√£o for resolvido com este runbook:

1. **Pesquisar Issues GitHub** ‚Üí https://github.com/seu-repo/issues
2. **Logs Detalhados** ‚Üí Coletar todos os logs e compartilhar
3. **Reproducible Example** ‚Üí Criar minimal test case
4. **Stack Overflow** ‚Üí Procurar por tags: `airflow`, `pyspark`, `docker`
5. **Community Slack** ‚Üí Airflow Community, PySpark Community
6. **Suporte Comercial** ‚Üí Se usando Astronomer ou Databricks

---

**Vers√£o:** 1.1  
**Data de Cria√ß√£o:** 1 de Fevereiro de 2026  
**Data de Atualiza√ß√£o:** 1 de Fevereiro de 2026  
**Pr√≥xima Revis√£o:** 1 de Mar√ßo de 2026  
**Respons√°vel:** Data Engineering Team

### Hist√≥rico de Vers√µes

| Vers√£o | Data | Mudan√ßas |
|--------|------|----------|
| 1.0 | 1 Feb 2026 | Vers√£o inicial com se√ß√µes principais |
| 1.1 | 1 Feb 2026 | Adicionado: Performance, Versionamento, Health Checks, Maintenance |

