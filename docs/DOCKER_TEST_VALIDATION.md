# DOCKER_TEST_VALIDATION.md - Guia Completo de Teste com Docker

**Date:** 2026-02-01  
**Status:** Ready for Testing  
**Purpose:** Validar que a soluÃ§Ã£o funciona corretamente em Docker  

---

## ğŸš€ PrÃ©-requisitos

### Verificar instalaÃ§Ã£o

```bash
# Docker deve estar instalado e rodando
docker --version
# Expected: Docker version 20.10+

docker-compose --version
# Expected: Docker Compose version 2.0+
```

Se Docker nÃ£o estÃ¡ rodando no Mac:
1. Abra **Docker Desktop** (procure em Applications)
2. Espere atÃ© que o Ã­cone na barra de menu mostre "Docker Desktop is running"

---

## ğŸ§ª Teste 1: Build das Imagens

```bash
cd /Users/thiagomarinhoesilva/Documents/GITHUB/teste_ambev/bees-brewery-case

# Build (isso vai baixar base images e instalar dependÃªncias)
# Esperado: ~5-10 minutos na primeira vez
docker-compose build

# ValidaÃ§Ã£o esperada:
# âœ… Successfully tagged bees-brewery-case_airflow-webserver:latest
# âœ… Successfully tagged bees-brewery-case_spark-master:latest
# âœ… Successfully tagged bees-brewery-case_spark-worker:latest
```

---

## ğŸ§ª Teste 2: Iniciar Containers

```bash
# Iniciar em background
docker-compose up -d

# Esperado: 6 containers iniciando
# - postgres
# - airflow-webserver
# - airflow-scheduler
# - spark-master
# - spark-worker (pode levar alguns segundos)

# Validar que containers estÃ£o rodando
docker-compose ps

# Esperado output:
# NAME                                 STATUS
# bees-brewery-case-postgres-1         Up (healthy)
# bees-brewery-case-airflow-webserver-1   Up (healthy)
# bees-brewery-case-airflow-scheduler-1   Up (healthy)
# bees-brewery-case-spark-master-1     Up (healthy)
# bees-brewery-case-spark-worker-1     Up (healthy)
```

---

## ğŸ§ª Teste 3: Verificar Airflow UI

```bash
# Airflow deve estar disponÃ­vel em http://localhost:8080
# Abra no navegador: http://localhost:8080

# Credenciais padrÃ£o:
# Username: airflow
# Password: airflow

# Se aparecer login page: âœ… Airflow estÃ¡ rodando
# Se aparecer DAG "bees_brewery_medallion": âœ… DAG foi carregado
```

---

## ğŸ§ª Teste 4: Verificar Spark UI

```bash
# Spark Master deve estar disponÃ­vel em http://localhost:8081
# Abra no navegador: http://localhost:8081

# Esperado:
# - Status: Alive
# - Workers: 1
# - Cores: 2 (ou mais se sua mÃ¡quina tem mais)
# - Memory: DisponÃ­vel e alocado
```

---

## ğŸ§ª Teste 5: Rodar DAG Manualmente

```bash
# Dentro do container Airflow
docker-compose exec airflow-webserver bash

# Agora vocÃª estÃ¡ DENTRO do container:
# 1. Unpause a DAG
airflow dags unpause bees_brewery_medallion

# 2. Trigger manualmente
airflow dags test bees_brewery_medallion 2026-02-01

# Esperado output:
# [2026-02-01 00:00:00,000] {bash_operator.py:123} INFO - Running command: ['python', ...]
# [2026-02-01 00:00:00,000] {bash_operator.py:123} INFO - Task exited with return code 0

# 3. Sair do container
exit
```

---

## ğŸ§ª Teste 6: Verificar Datalake

```bash
# Ver estrutura de diretÃ³rios criada
ls -la ./datalake/

# Esperado apÃ³s rodar DAG:
# datalake/
# â”œâ”€â”€ bronze/     (dados brutos da API)
# â”œâ”€â”€ silver/     (dados transformados)
# â””â”€â”€ gold/       (dados agregados)

# Validar Parquet files foram criados
find ./datalake -name "*.parquet" -type f

# Esperado: vÃ¡rios arquivos .parquet em cada layer
```

---

## ğŸ§ª Teste 7: Rodar Testes Automatizados

```bash
# Dentro do container Airflow
docker-compose exec airflow-webserver bash

# Rodar testes unitÃ¡rios
cd /opt/airflow
pytest tests/ -v --cov=spark_jobs --cov-report=term-missing

# Esperado:
# tests/test_ingestion.py::test_ingestion_job_init PASSED
# tests/test_transformation.py::test_transformation_extracts_bronze PASSED
# tests/test_aggregation.py::test_aggregation_job_init PASSED
# tests/test_architecture.py::test_full_pipeline PASSED
#
# ================ 10 passed in 2.34s ================
# Coverage: 85%
```

---

## ğŸ§ª Teste 8: Verificar Logs

```bash
# Ver logs de um container especÃ­fico
docker-compose logs airflow-webserver -f

# Ver logs do Scheduler
docker-compose logs airflow-scheduler -f

# Ver logs do Spark Master
docker-compose logs spark-master -f

# Esperado: logs sem erros crÃ­ticos
```

---

## ğŸ§ª Teste 9: Verificar Conectividade Entre Containers

```bash
# Dentro do Airflow container
docker-compose exec airflow-webserver bash

# Testar conexÃ£o com Spark Master
python3 << EOF
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("test") \
    .master("spark://spark-master:7077") \
    .getOrCreate()

print("âœ… Spark connection OK")
spark.stop()
EOF

# Esperado: âœ… Spark connection OK
```

---

## ğŸ§ª Teste 10: Parar Containers

```bash
# Parar todos os containers
docker-compose down

# Esperado: containers stopped and removed

# Validar que pararam
docker ps

# Esperado: lista vazia (ou apenas containers de outros projetos)
```

---

## ğŸ¯ TESTE COMPLETO DA DAG: Logs e Arquivos de SaÃ­da

### VisÃ£o Geral do Pipeline

A DAG `bees_brewery_medallion` executa 5 tarefas em sequÃªncia:

```
pipeline_start â†’ ingestion_bronze â†’ transformation_silver â†’ aggregation_gold â†’ pipeline_end
```

**Fluxo de dados esperado:**
- **Bronze:** Dados brutos da API (JSON normalizado em Parquet)
- **Silver:** Dados limpos e transformados
- **Gold:** Dados agregados para anÃ¡lises

---

### ğŸ“‹ PARTE 1: Preparar Ambiente para Teste

```bash
# 1. Ir para diretÃ³rio do projeto
cd /Users/thiagomarinhoesilva/Documents/GITHUB/teste_ambev/bees-brewery-case

# 2. Limpar containers anteriores (se existirem)
docker-compose down -v

# 3. Construir imagens
docker-compose build

# Esperado:
# âœ… Successfully tagged bees-brewery-case_airflow-webserver:latest
# âœ… Successfully tagged bees-brewery-case_spark-master:latest
# âœ… Successfully tagged bees-brewery-case_spark-worker:latest

# 4. Iniciar containers em background
docker-compose up -d

# 5. Aguardar inicializaÃ§Ã£o completa (30-60 segundos)
sleep 30

# 6. Validar que containers estÃ£o saudÃ¡veis
docker-compose ps

# Esperado output:
# STATUS = "Up" e "healthy" (ou "Up" sem a parte de health ainda)
```

---

### ğŸ“Š PARTE 2: Validar Estado Inicial da DAG

```bash
# 1. Acessar container do Airflow
docker-compose exec airflow-webserver bash

# Agora vocÃª estÃ¡ DENTRO do container Airflow
# Todos os comandos a seguir rodam DENTRO do container

# 2. Verificar que DAG estÃ¡ registrada
airflow dags list | grep bees_brewery_medallion

# Esperado output:
# bees_brewery_medallion | /opt/airflow/dags/bees_brewery_dag.py | False

# 3. Verificar tarefas da DAG
airflow tasks list bees_brewery_medallion

# Esperado output:
# pipeline_start
# ingestion_bronze
# transformation_silver
# aggregation_gold
# pipeline_end

# 4. Unpause a DAG (necessÃ¡rio para rodar)
airflow dags unpause bees_brewery_medallion

# Esperado:
# Dag: bees_brewery_medallion, paused: False
```

---

### ğŸš€ PARTE 3: Executar a DAG Manualmente

```bash
# AINDA DENTRO DO CONTAINER AIRFLOW

# OpÃ§Ã£o A: Test mode (mais rÃ¡pido, para debug)
airflow dags test bees_brewery_medallion 2026-02-01

# OpÃ§Ã£o B: Trigger normal (simula execuÃ§Ã£o real)
# airflow dags trigger bees_brewery_medallion --exec-date 2026-02-01

# â³ Aguarde 2-5 minutos para execuÃ§Ã£o completa
# VocÃª verÃ¡ muitas linhas de log enquanto executa

# Sinais de sucesso:
# âœ… [2026-02-01 XX:XX:XX,XXX] {bash_operator.py:123} INFO - Running command: ['echo', ...]
# âœ… [2026-02-01 XX:XX:XX,XXX] {python_operator.py:180} INFO - Task exited with return code 0
# âœ… Ingestion completed! XXX records written to bronze/breweries/...
```

---

### ğŸ“ PARTE 4: Monitorar Logs da DAG em Tempo Real

**Em outro terminal (Terminal 2):**

```bash
# Enquanto a DAG estÃ¡ rodando, monitore os logs

cd /Users/thiagomarinhoesilva/Documents/GITHUB/teste_ambev/bees-brewery-case

# Ver logs do Airflow Scheduler
docker-compose logs -f airflow-scheduler

# Esperado (deve haver logs da execuÃ§Ã£o da DAG):
# [2026-02-01 XX:XX:XX,XXX] {scheduler.py:xxx} INFO - Running <TaskInstance: bees_brewery_medallion.ingestion_bronze 2026-02-01T00:00:00+00:00 [running]> on worker...
```

**Em um terceiro terminal (Terminal 3):**

```bash
# Ver logs do Spark Master durante execuÃ§Ã£o dos jobs

docker-compose logs -f spark-master

# Esperado:
# 26/02/01 XX:XX:XX INFO Master: Registering worker...
# 26/02/01 XX:XX:XX INFO MasterWebUI: Binding MasterWebUI to 0.0.0.0
```

---

### ğŸ“‚ PARTE 5: Validar Arquivos de SaÃ­da - Bronze Layer

**De volta no Terminal 1 (container Airflow), apÃ³s DAG completar:**

```bash
# AINDA DENTRO DO CONTAINER AIRFLOW

# 1. Listar estrutura do datalake
ls -la /opt/airflow/datalake/

# Esperado:
# drwxr-xr-x  bronze/
# drwxr-xr-x  silver/
# drwxr-xr-x  gold/

# 2. Verificar dados Bronze (raw)
ls -la /opt/airflow/datalake/bronze/breweries/

# Esperado:
# drwxr-xr-x  created_at=2026-02-01/

# 3. Ver arquivos Parquet em Bronze
find /opt/airflow/datalake/bronze -name "*.parquet" -type f

# Esperado:
# /opt/airflow/datalake/bronze/breweries/created_at=2026-02-01/part-00000-xxx.snappy.parquet
# (pode haver mÃºltiplos part-XXXXX files)

# 4. Contar linhas em Bronze
python3 << 'EOF'
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("test").getOrCreate()
df = spark.read.parquet("/opt/airflow/datalake/bronze/breweries/created_at=2026-02-01")
print(f"âœ… Bronze Records: {df.count()}")
print(f"âœ… Bronze Schema: {df.schema}")
df.show(5)
EOF

# Esperado output:
# âœ… Bronze Records: XXX (nÃºmero de cervejarias da API)
# âœ… Bronze Schema: StructType([...])
# Mostra 5 primeiras linhas com dados brutos
```

---

### ğŸ“‚ PARTE 6: Validar Arquivos de SaÃ­da - Silver Layer

```bash
# AINDA DENTRO DO CONTAINER AIRFLOW

# 1. Verificar dados Silver (transformados)
ls -la /opt/airflow/datalake/silver/

# Esperado:
# drwxr-xr-x  breweries_cleaned/

# 2. Ver arquivos Parquet em Silver
find /opt/airflow/datalake/silver -name "*.parquet" -type f

# Esperado:
# /opt/airflow/datalake/silver/breweries_cleaned/created_at=2026-02-01/part-00000-xxx.snappy.parquet

# 3. Validar transformaÃ§Ã£o (Silver deve ter menos colunas/dados limpos)
python3 << 'EOF'
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("test").getOrCreate()

print("=" * 60)
print("COMPARAÃ‡ÃƒO: BRONZE vs SILVER")
print("=" * 60)

# Bronze
bronze_df = spark.read.parquet("/opt/airflow/datalake/bronze/breweries/created_at=2026-02-01")
print(f"\nğŸ“Š BRONZE (Raw):")
print(f"  Records: {bronze_df.count()}")
print(f"  Columns: {len(bronze_df.columns)}")
print(f"  Column names: {bronze_df.columns}")

# Silver
silver_df = spark.read.parquet("/opt/airflow/datalake/silver/breweries_cleaned/created_at=2026-02-01")
print(f"\nğŸ“Š SILVER (Cleaned):")
print(f"  Records: {silver_df.count()}")
print(f"  Columns: {len(silver_df.columns)}")
print(f"  Column names: {silver_df.columns}")

print(f"\nâœ… Sample Silver data:")
silver_df.show(5)

spark.stop()
EOF

# Esperado:
# SILVER deve ter:
#   - Mesmo nÃºmero ou menos registros (outliers removidos)
#   - Colunas renomeadas/limpas
#   - Dados sem valores nulos em campos importantes
#   - Timestamp de transformaÃ§Ã£o adicionado
```

---

### ğŸ“‚ PARTE 7: Validar Arquivos de SaÃ­da - Gold Layer

```bash
# AINDA DENTRO DO CONTAINER AIRFLOW

# 1. Verificar dados Gold (agregados)
ls -la /opt/airflow/datalake/gold/

# Esperado:
# drwxr-xr-x  breweries_stats/

# 2. Ver arquivos Parquet em Gold
find /opt/airflow/datalake/gold -name "*.parquet" -type f

# Esperado:
# /opt/airflow/datalake/gold/breweries_stats/created_at=2026-02-01/part-00000-xxx.snappy.parquet

# 3. Validar agregaÃ§Ãµes (Gold deve ter estadÃ­sticas por grupo)
python3 << 'EOF'
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("test").getOrCreate()

gold_df = spark.read.parquet("/opt/airflow/datalake/gold/breweries_stats/created_at=2026-02-01")

print("=" * 60)
print("GOLD LAYER (Agregado para Analytics)")
print("=" * 60)
print(f"\nğŸ“Š EstatÃ­sticas:")
print(f"  Total de grupos/agregaÃ§Ãµes: {gold_df.count()}")
print(f"  Colunas: {gold_df.columns}")

print(f"\nğŸ“ˆ Sample agregado:")
gold_df.show(10)

print(f"\nğŸ“Š Schema do Gold:")
gold_df.printSchema()

spark.stop()
EOF

# Esperado:
# GOLD deve ter agregaÃ§Ãµes como:
#   - Count por brewery_type (estado, tipo, etc.)
#   - Stats (min, max, avg) de valores numÃ©ricos
#   - Dados prontos para BI/Dashboard
```

---

### ğŸ“œ PARTE 8: Validar Logs Estruturados

```bash
# AINDA DENTRO DO CONTAINER AIRFLOW

# 1. Ver logs de execuÃ§Ã£o da DAG
cat /opt/airflow/logs/dag_id=bees_brewery_medallion/*/2026-02-01T00:00:00*/task_id=*/attempt=1.log

# Alternativamente, ver diretÃ³rio de logs
find /opt/airflow/logs -name "*.log" -type f | head -10

# 2. Ver log especÃ­fico de uma tarefa (exemplo: ingestion_bronze)
cat /opt/airflow/logs/dag_id=bees_brewery_medallion/run_id=manual__2026-02-01T00:00:00*/task_id=ingestion_bronze/attempt=1.log 2>/dev/null || echo "Log ainda nÃ£o disponÃ­vel"

# 3. Extrair informaÃ§Ãµes importantes dos logs
python3 << 'EOF'
import glob
import os

# Procurar por logs da execuÃ§Ã£o
log_dir = "/opt/airflow/logs/dag_id=bees_brewery_medallion"
log_files = glob.glob(f"{log_dir}/**/attempt=1.log", recursive=True)

print(f"Found {len(log_files)} log files")
print("\nProcurando por keywords importantes...\n")

keywords = [
    "âœ…", "âŒ", "ERROR", "WARN", "completed", "failed", 
    "records written", "rows processed", "Schema validation"
]

for log_file in sorted(log_files)[:3]:  # Primeiros 3 logs
    print(f"\n{'='*60}")
    print(f"File: {log_file.split('/')[-3]}")
    print(f"{'='*60}")
    
    with open(log_file, 'r') as f:
        for line in f:
            if any(kw in line for kw in keywords):
                print(line.strip())
EOF
```

---

### ğŸ” PARTE 9: ValidaÃ§Ã£o Completa de Integridade de Dados

```bash
# AINDA DENTRO DO CONTAINER AIRFLOW

# Script completo de validaÃ§Ã£o end-to-end

python3 << 'EOF'
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, count, isnull, countDistinct
import sys

spark = SparkSession.builder \
    .appName("DataQualityValidation") \
    .getOrCreate()

print("\n" + "="*70)
print("ğŸ” VALIDAÃ‡ÃƒO COMPLETA: Pipeline de Dados BEES Brewery")
print("="*70)

# --- BRONZE LAYER ---
print("\nğŸ“¦ BRONZE LAYER (Raw Data)")
print("-" * 70)

try:
    bronze = spark.read.parquet("/opt/airflow/datalake/bronze/breweries/created_at=2026-02-01")
    
    bronze_count = bronze.count()
    print(f"âœ… Bronze records: {bronze_count}")
    
    if bronze_count == 0:
        print("âŒ ERRO: Bronze layer vazia!")
        sys.exit(1)
    
    print(f"âœ… Bronze columns: {len(bronze.columns)} - {bronze.columns}")
    
    # Verificar nulos
    null_counts = bronze.select([count(isnull(col(c))).alias(c) for c in bronze.columns]).collect()[0]
    print(f"âœ… Valores nulos por coluna: {null_counts.asDict()}")
    
except Exception as e:
    print(f"âŒ Erro ao validar Bronze: {e}")
    sys.exit(1)

# --- SILVER LAYER ---
print("\nğŸ”„ SILVER LAYER (Transformed Data)")
print("-" * 70)

try:
    silver = spark.read.parquet("/opt/airflow/datalake/silver/breweries_cleaned/created_at=2026-02-01")
    
    silver_count = silver.count()
    print(f"âœ… Silver records: {silver_count}")
    
    if silver_count == 0:
        print("âš ï¸  Aviso: Silver layer vazia")
    else:
        print(f"âœ… Silver columns: {len(silver.columns)} - {silver.columns}")
        
        # ComparaÃ§Ã£o com Bronze
        reduction = ((bronze_count - silver_count) / bronze_count * 100) if bronze_count > 0 else 0
        print(f"âœ… ReduÃ§Ã£o de dados: {reduction:.2f}% (outliers removidos)")
        
        # Mostrar sample
        print(f"\nğŸ“‹ Sample (5 linhas):")
        silver.show(5, truncate=False)
        
except Exception as e:
    print(f"âš ï¸  Aviso ao validar Silver: {e}")

# --- GOLD LAYER ---
print("\nğŸ“Š GOLD LAYER (Aggregated Data)")
print("-" * 70)

try:
    gold = spark.read.parquet("/opt/airflow/datalake/gold/breweries_stats/created_at=2026-02-01")
    
    gold_count = gold.count()
    print(f"âœ… Gold records (agregaÃ§Ãµes): {gold_count}")
    
    if gold_count == 0:
        print("âš ï¸  Aviso: Gold layer vazia")
    else:
        print(f"âœ… Gold columns: {len(gold.columns)} - {gold.columns}")
        
        print(f"\nğŸ“ˆ AgregaÃ§Ãµes Gold (amostra):")
        gold.show(5, truncate=False)
        
except Exception as e:
    print(f"âš ï¸  Aviso ao validar Gold: {e}")

# --- RESUMO FINAL ---
print("\n" + "="*70)
print("âœ… VALIDAÃ‡ÃƒO CONCLUÃDA COM SUCESSO")
print("="*70)
print(f"""
ğŸ“Š RESUMO FINAL:
  Bronze:  {bronze_count} registros (dados brutos)
  Silver:  {silver_count if silver_count else 'N/A'} registros (dados limpos)
  Gold:    {gold_count if gold_count else 'N/A'} registros (dados agregados)
  
âœ… Pipeline completou todas as 3 camadas (Bronze â†’ Silver â†’ Gold)
""")

spark.stop()
EOF

# Esperado output:
# âœ… VALIDAÃ‡ÃƒO CONCLUÃDA COM SUCESSO
# Mostra contagem de registros em cada camada
# Mostra que dados fluiram corretamente atravÃ©s do pipeline
```

---

### ğŸ“‹ PARTE 10: Checklist de ValidaÃ§Ã£o da DAG

```bash
# Fora do container, ou dentro dele para verificar

# 1. Verificar via Airflow UI (navegador)
# http://localhost:8080
# - Procure por: bees_brewery_medallion
# - Deve aparecer "Last Run: 2026-02-01"
# - Deve mostrar "Success" com checkmark verde

# 2. Verificar diretÃ³rios de saÃ­da (fora do container)
ls -la /Users/thiagomarinhoesilva/Documents/GITHUB/teste_ambev/bees-brewery-case/datalake/

# Esperado:
# drwxr-xr-x  bronze/
# drwxr-xr-x  silver/
# drwxr-xr-x  gold/

# 3. Contar arquivos Parquet
find /Users/thiagomarinhoesilva/Documents/GITHUB/teste_ambev/bees-brewery-case/datalake -name "*.parquet" | wc -l

# Esperado: > 0 (vÃ¡rios arquivos parquet criados)

# 4. Verificar logs do container
docker-compose logs airflow-scheduler | grep "bees_brewery_medallion" | tail -20

# Esperado: logs mostrando execuÃ§Ã£o bem-sucedida das tarefas
```

---

### ğŸ¯ PARTE 11: ValidaÃ§Ã£o Visual - Airflow UI

```
1. Acesse: http://localhost:8080
   Username: admin / Password: admin

2. Procure pelo DAG "bees_brewery_medallion"

3. Verifique:
   âœ… DAG estÃ¡ na lista
   âœ… Status mostrado como "active" (verde)
   âœ… "Paused" estÃ¡ desligado (False)

4. Clique no DAG para ver:
   âœ… Graph View: 5 tarefas (start â†’ bronze â†’ silver â†’ gold â†’ end)
   âœ… Tree View: Ãšltima execuÃ§Ã£o em 2026-02-01
   âœ… Todos os boxes aparecem em verde (sucesso)

5. Clique em cada tarefa para ver logs:
   âœ… pipeline_start: "echo Starting..."
   âœ… ingestion_bronze: "Starting ingestion from Open Brewery DB API"
   âœ… transformation_silver: "Starting transformation job"
   âœ… aggregation_gold: "Starting aggregation job"
   âœ… pipeline_end: "echo Pipeline completed successfully"
```

---

### âš ï¸ TROUBLESHOOTING: Se algo falhar

```bash
# Se DAG falhar, procure por erros:

# 1. Ver erro detalhado
docker-compose logs airflow-scheduler | grep -A 10 "ERROR"

# 2. Ver erro do Spark
docker-compose logs spark-master | grep -A 5 "ERROR"

# 3. Verificar se API estÃ¡ respondendo
docker-compose exec airflow-webserver bash
python3 << 'EOF'
import requests
url = "https://api.openbrewerydb.org/breweries?per_page=1"
try:
    resp = requests.get(url, timeout=10)
    print(f"API Status: {resp.status_code}")
    print(f"Response: {resp.json()[:1]}")
except Exception as e:
    print(f"API Error: {e}")
EOF

# 4. Verificar storage/disco
du -sh /Users/thiagomarinhoesilva/Documents/GITHUB/teste_ambev/bees-brewery-case/datalake/
df -h

# 5. Verificar memÃ³ria do Docker
docker stats
```

---

### ğŸ“Š RESUMO: O que deve acontecer

```
InÃ­cio:
  â””â”€ docker-compose up -d
     â””â”€ Aguarda 30-60 segundos

DAG Trigger:
  â””â”€ airflow dags test bees_brewery_medallion 2026-02-01
     â””â”€ Tarefa 1 (start): Echo inicial
     â””â”€ Tarefa 2 (ingestion): 
        â”œâ”€ Fetch da API OpenBreweryDB
        â”œâ”€ Normaliza dados (strings)
        â”œâ”€ Valida schema
        â””â”€ Salva em: datalake/bronze/breweries/created_at=2026-02-01/ (Parquet)
     
     â””â”€ Tarefa 3 (transformation):
        â”œâ”€ LÃª dados de Bronze
        â”œâ”€ Remove outliers/nulos
        â”œâ”€ Renomeia colunas
        â”œâ”€ Adiciona timestamps
        â””â”€ Salva em: datalake/silver/breweries_cleaned/created_at=2026-02-01/ (Parquet)
     
     â””â”€ Tarefa 4 (aggregation):
        â”œâ”€ LÃª dados de Silver
        â”œâ”€ Agrupa por brewery_type/state/etc
        â”œâ”€ Calcula stats (count, min, max, avg)
        â””â”€ Salva em: datalake/gold/breweries_stats/created_at=2026-02-01/ (Parquet)
     
     â””â”€ Tarefa 5 (end): Echo final

Resultado Final:
  âœ… Arquivo de partiÃ§Ã£o em cada camada
  âœ… Logs mostrando "Task exited with return code 0"
  âœ… Estrutura Medallion completa: Bronze â†’ Silver â†’ Gold
```

---

**ğŸ‰ Sucesso:** Se chegou aqui e tudo passou, seu pipeline estÃ¡ pronto para produÃ§Ã£o!

---

## ğŸ“Š Checklist de ValidaÃ§Ã£o

```
âœ… PRÃ‰-REQUISITOS
  â˜ Docker instalado
  â˜ Docker daemon rodando
  â˜ Docker Compose instalado
  â˜ MÃ­nimo 4GB RAM disponÃ­vel para Docker

âœ… BUILD
  â˜ Dockerfile.airflow build com sucesso
  â˜ Dockerfile.spark build com sucesso
  â˜ Requirements.txt instalado corretamente

âœ… CONTAINERS
  â˜ Postgres iniciado e healthy
  â˜ Airflow Webserver iniciado e healthy
  â˜ Airflow Scheduler iniciado e healthy
  â˜ Spark Master iniciado
  â˜ Spark Worker iniciado e conectado ao Master

âœ… AIRFLOW
  â˜ UI acessÃ­vel em http://localhost:8080
  â˜ DAG "bees_brewery_medallion" visÃ­vel
  â˜ DAG pode ser unpaused
  â˜ DAG pode ser triggerado manualmente

âœ… SPARK
  â˜ UI acessÃ­vel em http://localhost:8081
  â˜ Worker registrado no Master
  â˜ AplicaÃ§Ãµes podem ser submitidas

âœ… PIPELINE
  â˜ Ingestion Job executa com sucesso
  â˜ Transformation Job executa com sucesso
  â˜ Aggregation Job executa com sucesso
  â˜ Dados aparecem em datalake/bronze/
  â˜ Dados aparecem em datalake/silver/
  â˜ Dados aparecem em datalake/gold/

âœ… TESTES
  â˜ Testes unitÃ¡rios rodam com sucesso
  â˜ Cobertura > 80%
  â˜ Nenhum teste falha
  â˜ Testes de integraÃ§Ã£o passam

âœ… DADOS
  â˜ Dados Bronze: raw formato original
  â˜ Dados Silver: cleaned e enriched
  â˜ Dados Gold: aggregated para analytics
  â˜ Parquet files foram criados
  â˜ Schema validaÃ§Ã£o passou

âœ… ERRO HANDLING
  â˜ DataQualityException funciona corretamente
  â˜ StorageException Ã© capturada
  â˜ Logging estruturado estÃ¡ ativo
  â˜ Retry policies funcionam em Airflow

âœ… CLEANUP
  â˜ docker-compose down remove containers
  â˜ Volumes persistem (ou sÃ£o deletados se --volumes)
```

---

## ğŸ”§ Troubleshooting

### âŒ Erro: "Cannot connect to Docker daemon"

```bash
# SoluÃ§Ã£o 1: Iniciar Docker Desktop
open /Applications/Docker.app

# SoluÃ§Ã£o 2: Aguardar que inicialize completamente
sleep 30

# SoluÃ§Ã£o 3: Validar que daemon estÃ¡ respondendo
docker ps
```

### âŒ Erro: "Port 8080 is already in use"

```bash
# Encontrar processo usando porta 8080
lsof -i :8080

# Matar processo
kill -9 <PID>

# Ou usar porta diferente
docker-compose up -d -p 8090:8080
```

### âŒ Erro: "Insufficient disk space"

```bash
# Limpar images nÃ£o usadas
docker system prune -a

# Liberar espaÃ§o (cuidado!)
docker image prune
```

### âŒ Erro: "Container exited with code 1"

```bash
# Ver logs detalhados
docker-compose logs <service-name>

# Exemplo:
docker-compose logs airflow-webserver
```

### âŒ Erro: "Spark Worker nÃ£o conecta ao Master"

```bash
# Verificar que spark-master estÃ¡ healthy
docker-compose logs spark-master

# Esperado: "Started MasterWebUI at ..."

# Verificar network
docker network inspect bees-brewery-case_default

# Esperado: ambos master e worker no mesmo network
```

---

## ğŸ“ˆ Monitoramento Durante ExecuÃ§Ã£o

### Monitorar em Tempo Real

```bash
# Terminal 1: Ver logs do Scheduler
docker-compose logs airflow-scheduler -f

# Terminal 2: Ver logs do Airflow Webserver
docker-compose logs airflow-webserver -f

# Terminal 3: Ver logs do Spark Master
docker-compose logs spark-master -f

# Terminal 4: Executar comandos
docker-compose exec airflow-webserver bash
```

### Verificar MÃ©tricas

```bash
# CPU e Memory usage dos containers
docker stats

# Esperado:
# CONTAINER                   CPU %    MEM USAGE / LIMIT
# bees-brewery-case-postgres-1      0.5%     150MB / 8GB
# bees-brewery-case-airflow-webserver-1  2%  500MB / 8GB
```

---

## âœ… ValidaÃ§Ã£o Final

Se todos os testes passaram, vocÃª tem:

âœ… **Arquitetura Modular**
- CÃ³digo bem separado (config, core, jobs, schemas)
- Dependency injection funcionando
- Multi-environment suportado

âœ… **Pipeline EscalÃ¡vel**
- Medallion architecture (Bronze â†’ Silver â†’ Gold)
- Spark partitioning funcionando
- Airflow orchestration rodando

âœ… **Robustez**
- Error handling com retry policies
- Data quality validation ativa
- Logging estruturado

âœ… **Deployment Ready**
- Docker compose levanta tudo
- Todos containers comunicam
- Pipeline executa end-to-end

âœ… **DocumentaÃ§Ã£o Completa**
- ADRs explicam decisÃµes
- REQUIREMENTS_MAPPING mostra rastreabilidade
- README descreve como rodar

---

## ğŸ PrÃ³ximas Etapas

Depois que validar com Docker:

1. **Commit no Git**
   ```bash
   git add .
   git commit -m "feat: production-ready data pipeline with Docker"
   git push origin main
   ```

2. **Preparar para apresentaÃ§Ã£o**
   - Ter Docker rodando
   - Ter Airflow UI acessÃ­vel
   - Ter testes passando

3. **DemonstraÃ§Ã£o para Bees**
   - Mostrar DAG no Airflow
   - Rodar pipeline manualmente
   - Mostrar dados em cada layer
   - Explicar decisÃµes tÃ©cnicas via ADRs

---

**Last Updated:** 2026-02-01  
**Status:** âœ… Ready for Docker Testing  
**Next Step:** Start Docker daemon and run tests
